\documentclass[a4paper,kul]{kulakarticle} %options: kul or kulak (default)

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{subcaption}
\newlength{\twosubht}
\newsavebox{\twosubbox}
\graphicspath{{../Figures/}{../Matlab/}{/}}
\usepackage[outdir=./]{epstopdf}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{gensymb}
\setcounter{MaxMatrixCols}{21}

\usepackage{etoolbox,refcount}
\usepackage{multicol}

\newcounter{countitems}
\newcounter{nextitemizecount}
\newcommand{\setupcountitems}{%
	\stepcounter{nextitemizecount}%
	\setcounter{countitems}{0}%
	\preto\item{\stepcounter{countitems}}%
}
\makeatletter
\newcommand{\computecountitems}{%
	\edef\@currentlabel{\number\c@countitems}%
	\label{countitems@\number\numexpr\value{nextitemizecount}-1\relax}%
}
\newcommand{\nextitemizecount}{%
	\getrefnumber{countitems@\number\c@nextitemizecount}%
}
\newcommand{\previtemizecount}{%
	\getrefnumber{countitems@\number\numexpr\value{nextitemizecount}-1\relax}%
}
\makeatother    
\newenvironment{AutoMultiColItemize}{%
	\ifnumcomp{\nextitemizecount}{>}{3}{\begin{multicols}{2}}{}%
		\setupcountitems\begin{itemize}}%
		{\end{itemize}%
		\unskip\computecountitems\ifnumcomp{\previtemizecount}{>}{3}{\end{multicols}}{}}

\usepackage{pdflscape}

\date{Academic year 2021 -- 2022}
\address{
  Faculty of Engineering Science \\
  Department of Mechanical Engineering \\
  Control theory \texttt{[H04X3a]}}
\title{Report Assignment 3: State Feedback and State Estimation}
\author{Matthias Derez, Toon Servaes}


\begin{document}

\maketitle

\tableofcontents
\listoffigures

\tikzstyle{block} = [draw, rectangle, 
minimum height=3em, minimum width=6em]
\tikzstyle{blocksmall} = [draw, rectangle, 
minimum height=3em, minimum width=3em]
\tikzstyle{sum} = [draw, circle, node distance=1cm]
\tikzstyle{input} = [coordinate]
\tikzstyle{output} = [coordinate]
\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]



\newpage
\section{Design of the State Feedback Controller}
In this Section, a state feedback controller is designed in order to control the position of the cart while driving on a straight line. This position control loop is then added on top of the velocity controllers designed in Assignment 2. 

\subsection{Input \& Output}
Figure \ref{fig:flowdiagram} visualizes the discrete time LTI system that is examined in this assignment. The input and output are given by:
\begin{equation}
	\begin{split}
	\text{input } u(t) &= v(t) = r_w\omega(t) = \dot{x}(t) \\
	\text{output } y(t) &= -x(t)
	\end{split}
\end{equation}
where $v(t)$ is the velocity of the cart, $r_w = 0.033$m the radius of the wheels and $\omega$ the rotational velocity of the wheels. The minus sign in the output equation is due to choice of the coordinate system, so that $-x$ represents a positive value. 

\subsection{State Space Model}
There is only one state, the position $x$, so the matrices in the state equation (and measurement equation) are scalars. 
\\\\
Continuous state space model:
\begin{equation}
\left\{
	\begin{split}
	\dot{x}(t) &= v(t) = u(t) \qquad &\text{state equation} \\
	y(t) &= -x(t) &\text{measurement equation}
	\end{split}
	\right.
\end{equation}
Discretization using Forward-Euler scheme:
\begin{equation}
	\dot{x}[k] = \frac{x[k+1] - x[k]}{T_s} + O(T_s^2)
\end{equation}
leads to:
\begin{equation}
\left\{
\begin{split}
\dot{x}[t+1] &= x[k] + T_s u[k] \qquad &\text{state equation} \\
y[t] &= -x[t] &\text{measurement equation}
\end{split}
\right.
\end{equation}
with $T_s$ the sampling time of $0.01$ s. From the general discretized state space form, one can deduce that $A = 1$, $B = T_s$, $C = -1$ and $D = 0$.

\subsection{Close Loop Transfer Function}
\label{subsec:tf}
Assuming full state feedback, the closed loop transfer function is:
\begin{equation}
	\begin{split}
	H(z) = \frac{Y(z)}{R(z)} &= (C-DK)(z - A + BK)^{-1}B + D \\
	&= -(z-1 + T_s K)^{-1} T_s \\
	&= \frac{-T_s}{z-1+T_sK}
	\end{split}
\end{equation}
with $K$ the state feedback gain. Subsequently, the closed loop system has one pole, which is located at
\begin{equation}
	p_d = 1 - T_s K
\end{equation}
This equation indicates that the pole moves to the left for increasing K, or inversely, move to the right for decreasing K, as seen in Figure \ref{fig:poles}. In the discrete time domain, the system is stable if the poles are within the unit circle. For this particular system, this means $0 < K < 200$ Hz. 
\\\\
However, discrete time poles on the negative side of the real axis have no physical meaning, as these are purely digital effects that have no use in practice. Thus, the state feedback gain is restricted as follows: $0 < K \le 100$ Hz.


\begin{figure}[htp]
	\centering
	\resizebox{.7\linewidth}{!}{
	\begin{tikzpicture}[auto, node distance=2cm,>=latex']
	% We start by placing the blocks
	\node [input, name=input] {};
	\node [sum, right of=input, node distance = 1.8cm] (sum) {};
	\node [block, right of=sum, node distance=3cm] (controller) {$qx = Ax + Bu$};
	\draw [->] (sum) -- node[name=extra, anchor=north] {$u[k]$} (controller);
	\node [blocksmall, right of=controller,
	node distance=3.5cm] (system) {$C$};
	% We draw an edge between the controller and system block to 
	% calculate the coordinate u. We need it to place the measurement block. 
	\draw [->] (controller) -- node[name=u] {$x[k]$} (system);
	\node [sum, right of=system, node distance=2cm] (disturbance) {};
	\node [blocksmall, above of=u, node distance = 1.3cm] (gd) {$D$};
	\node [output, right of=disturbance] (output) {};
	\node [blocksmall, below of=controller, node distance = 1.5cm] (measurements) {$-K$};
	
	% Once the nodes are placed, connecting them is easy. 
	\draw [draw,->] (input) -- node {$r[k]$} (sum);
	\draw [->] (system) -- node[pos=0.97] {$+$} (disturbance);
	\draw [->] (disturbance) -- node [name=y] {$y[k]$}(output);
	\draw [->] (extra) |- node {} (gd);
	\draw [->] (gd) -| node {} (disturbance);
	\draw [->] (u) |- (measurements);
	\draw [->] (measurements) -| node[pos=0.99] {$+$}  (sum);
	\end{tikzpicture}}
	\caption{Flow diagram of the closed loop system. \cite{tikz}}
	\label{fig:flowdiagram}
\end{figure}
\newpage
\noindent Furthermore, a pole that is close to the unit circle, e.g. for $K = 10$, leads to a slower responding system. Equivalently, a pole that is closer to the origin leads to a faster response. These conclusions are demonstrated by Figure \ref{fig:impulse_response}. 
\\\\
There are two limit cases. On the one hand, when the pole is located on the unit circle itself, the system is marginally stable. On the other hand, a pole which lies at the origin corresponds to an infinitely fast system. This would however mean that the control signal would be infinitely large, thus saturating the actuators. This limits the state feedback gain to $0 < K < 100$ Hz. So there is a trade-off between response time and cost in terms of required actuation signal. Both of these limit cases are depicted in Figure \ref{fig:impulse_response}. 
\\\\
The previously made conclusions can also be verified by transforming the poles to continuous time and plotting them in the imaginary plane. For continuous time poles, the further the pole lies from the imaginary axis (in the left hand plane), the faster the response. This is confirmed by Figure \ref{fig:poles cont}.




\begin{figure}[htp!]
	\centering
	\includegraphics[width=0.5\linewidth]{poles.eps}
	\caption{Discrete time pole locations of the closed-loop system for varying values of the state feedback gain.}
	\label{fig:poles}
\end{figure}

\begin{figure}[htp!]
	\centering
	\includegraphics[width=0.55\linewidth]{poles_cont.eps}
	\caption{Continuous time pole locations of the closed-loop system for varying values of the state feedback gain.} 
	\label{fig:poles cont}
\end{figure}

%\begin{figure}[htp!]
%	\centering
%	\includegraphics[width=0.55\textwidth]{impulse_response1.pdf}
%	\caption{Impulse response of the closed-loop system for varying values of the state feedback gain K.}
%	\label{fig:impulse_response1}
%\end{figure}
%
%\begin{figure}[htp!]
%	\centering
%	\includegraphics[width=0.55\textwidth]{impulse_response1.pdf}
%	\caption{Impulse response of the closed-loop system for varying values of the state feedback gain K.}
%	\label{fig:impulse_response3}
%\end{figure}


\begin{figure*}[htp!]
	\centering
	\begin{subfigure}[b]{0.55\textwidth}
		\centering
		\includegraphics[width=\textwidth]{impulse_response1.pdf}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.55\textwidth}  
		\centering 
		\includegraphics[width=\textwidth]{impulse_response3.pdf}
	\end{subfigure}
	\caption{Impulse response of the closed-loop system for varying values of the state feedback gain K.} 
	\label{fig:impulse_response}
\end{figure*}




\newpage
\section{Kalman Filter}
\subsection{Measurement Equation}
As previously elaborated, the measurement equation is equal to 
\begin{equation}
	y[t] = -x[t]
	\label{eq:eq7}
\end{equation}
so the C and D matrices of the state-space model are scalar values, respectively $-1$ and $0$. In this Section, these values are used to validate the principles of the Kalman filter on this system. To this extent, some mathematical derivations are done. 

\subsection{Kalman Gain}
\label{subsec:kalman_gain}
Firstly, an expression for the time-varying Kalmain gain $L_{k+1}$ is derived as a function of the state estimate covariance $\hat{P}_{k|k}$, the process noise covariance $Q$ and measurement noise covariance $R$. This starts from the following equations in Chapter 10 of \textit{Control Theory - Handouts} \cite{slidescontroltheory}:

\begin{align}
	\mathbf{L}_{k+1} &= \mathbf{\hat{P}}_{k+1|k} \mathbf{C}^T S_{k+1}^{-1} \label{eq:eq8}\\
	S_{k+1} &= \mathbf{C \hat{P}}_{k+1|k} \mathbf{C}^T + R_{k+1} \label{eq:eq9}\\
	\mathbf{\hat{P}}_{k+1|k} &= \mathbf{A} \mathbf{\hat{P}}_{k|k} \mathbf{A}^T + \mathbf{Q}_k \label{eq:eq10}
\end{align}

\noindent Where $S_{k+1}$ is the innovation covariance. All matrices and vectors are scalar values in this specific system, so from now on, the boldface notation is left out. Inserting Equations (\ref{eq:eq8}) and (\ref{eq:eq9}) in Equation (\ref{eq:eq10}) and using $A = 1$ and $C = -1$ yields:
\begin{equation}
	\begin{split}
	L_{k+1} &= -\left( \hat{P}_{k|k} + Q_k \right) \left( \hat{P}_{k+1|k} + R_{k+1} \right)^{-1} \\
	&= - \frac{\hat{P}_{k|k} + Q_k}{\hat{P}_{k+1|k} + R_{k+1}} \\
	&= - \frac{\hat{P}_{k|k} + Q_k}{\hat{P}_{k|k} + Q_k + R_{k+1}}
	\end{split}
	\label{eq:eq11}
\end{equation}
where Equation (\ref{eq:eq10}) was used again in the last step.
\\\\
Taking the limit for $Q_k \rightarrow \infty$ results in $L_{k+1} = -1$, which in turn leads to $\hat{x}_{k+1|k+1} = -y_{k+1}$. This is literally the measurement equation of the state-space model (\ref{eq:eq7}). One can explain this as follows: the larger $Q$, the greater the variation of the process noise, the less confidence in the model. Or equivalently, the more confidence in the measurement. In the extreme case, i.e. $Q_k \rightarrow \infty$, one has so little confidence in the model that the state equation is entirely neglected. 
\\\\
Next, taking the limit for $R_{k+1} \rightarrow \infty$ prompts $L_{k+1} = 0$, which results in $\hat{x}_{k+1|k+1} = \hat{x}_{k+1|k}$. The a priori state estimate is equal to the a posteriori state estimate, meaning that the correction step in the Kalman filter process is neglected. This is yet again easily explainable: the larger $R$, the greater the variation of the measurement noise, the less confidence in the measurement. Or equivalently, the more confidence in the model. The extreme case $R_{k+1} \rightarrow \infty$ has so little confidence in the measurement that the innovation residual is completely not taken into account, thus eliminating the correction step.

\subsection{Next State Estimate Covariance}
Secondly, an expression for the next state estimate covariance $\hat{P}_{k+1|k+1}$ is derived as a function of the previous state estimate covariance $\hat{P}_{k|k}$, the process noise covariance $Q$ and measurement noise covariance $R$. Again, starting from an equation given in the handouts: 
\begin{equation}
	\hat{P}_{k+1|k+1} = (1 - L_{k+1} C)\hat{P}_{k+1|k} = (1 + L_{k+1})\hat{P}_{k+1|k}
\end{equation}
Using Equations (\ref{eq:eq10}) and (\ref{eq:eq11}) yields:
\begin{equation}
	\begin{split}
	\hat{P}_{k+1|k+1} &= \left(1 - \frac{\hat{P}_{k|k} + Q_k}{\hat{P}_{k|k} + Q_k + R_{k+1}}\right) \hat{P}_{k+1|k} \\
	&= \frac{R_{k+1}}{\hat{P}_{k|k} + Q_k + R_{k+1}}\left(\hat{P}_{k|k} + Q_k\right)
	\end{split}
	\label{eq:eq13}
\end{equation}

\noindent Taking the limit for $Q_k \rightarrow \infty$ results in $\hat{P}_{k+1|k+1} = R_{k+1}$. Again,  $Q_k \rightarrow \infty$ indicates that there is zero confidence in the model, so only the measurements get used to adapt the state estimate. This way, the reliability of the estimator is purely based on the reliability of the measurement. In other words, the uncertainty on the state estimate evolves according to the measurement noise covariance. Whereas this uncertainty evolves depending on both the model and the measurements in normal operation of the filter.
\\\\
Further, the limit for $R_{k+1} \rightarrow \infty$ prompts $\hat{P}_{k+1|k+1} = \hat{P}_{k|k} + Q_k = \hat{P}_{k+1|k}$. Once more, $R_{k+1} \rightarrow \infty$ indicates zero confidence in the measurements. The a priori covariance matrix of the estimation error is equal to the a posteriori covariance matrix, so the correction step in neglected. In other words, the reliability of the estimator is purely based on the reliability of the model. In normal operation of the filter, $\hat{P}_{k+1|k+1} \preceq \hat{P}_{k+1|k}$, meaning that the uncertainty of the state estimate decreases, whereas in this limit case, the uncertainty does not decrease after the correction step, but it stays the same.

\subsection{Steady State Covariance}
\label{subsec:ss}
Now, an expression for the steady state covariance $\hat{P}_\infty$ and the related Kalman gain $L_\infty$ is obtained as a function of $Q$ and $R$. For this, $\hat{P}_{k|k} = \hat{P}_{k+1|k+1} = \hat{P}_\infty$, $R_{k+1} = R_{\infty}$ and $Q_k = Q_\infty$ are inserted in Equation (\ref{eq:eq13}):
\begin{equation}
	\hat{P}_\infty = \frac{R_{\infty}}{\hat{P}_{\infty} + Q_\infty + R_{\infty}}\left(\hat{P}_{\infty} + Q_\infty\right)
\end{equation}
Solving for $\hat{P}_\infty$ gives:
\begin{equation}
	\hat{P}_\infty = \frac{-Q_\infty \pm \sqrt{Q_\infty^2 + 4R_\infty Q_\infty}}{2}
\end{equation}
As all covariances must be positive numbers, the only solution for the steady state covariance is: 
\begin{equation}
\hat{P}_\infty = \frac{-Q_\infty + \sqrt{Q_\infty^2 + 4R_\infty Q_\infty}}{2}
\label{eq:eq16}
\end{equation}
Analogously, these steady state covariances are inserted in Equation (\ref{eq:eq11}) in order to find the related steady state Kalman gain:
\begin{equation}
L_\infty = - \frac{\hat{P}_\infty + Q_\infty}{\hat{P}_\infty + Q_\infty + R_\infty}
\label{eq:eq17}
\end{equation}
With $\hat{P}_\infty$ equal to Equation (\ref{eq:eq16}), $L_\infty$ is likewise expressed as a function of the steady state process noise covariance $Q_\infty$ and the steady state measurement noise covariance $R_\infty$.
\\\\
In steady state, i.e. $k \rightarrow \infty$, the optimal Kalman gain $L_{k+1}$ should converge to the estimator gain $L$ of a Linear Quadratic Estimator. This is verified by computing $L_\infty$ for various numerical values of $Q_\infty$ and $R_\infty$ using the derived equation. It is then compared to the result using the \texttt{dlqr(A',A'*C',Q,R)'} command in \texttt{Matlab}. Figure \ref{fig:gain_error} depicts the relative error between the LQE estimator gain and the steady state Kalman gain that is calculated using the derived formula. This is done for different combinations of $Q$ and $R$, where both are between $10^{-4}$ and $1$. The error is in the order of the machine precision, so one can conclude that the derived formula is correct.

\begin{figure}[htp!]
	\centering
	\includegraphics[width=.6\linewidth]{gain_error.eps}
	\caption{Relative error between the LQE estimator gain and the steady state Kalman gain.}
	\label{fig:gain_error}
\end{figure}

\subsection{Closed Loop Pole of the LQE}
\label{subsec:lqe}
Lastly, an expression for the closed-loop pole of the Linear Quadratic Estimator is derived as a function of $\frac{Q}{R}$. Generally, the estimator state equation is given by 
\begin{equation}
	\hat{x}_{k+1} = (A-LC) \hat{x}_k + (B-LD) u_k + L y_k
\end{equation}
In this way, the closed loop poles of the estimator are calculated as the eigenvalues of the matrix (A-LC):
\begin{equation}
	\text{det}(p_d I - (A-L_\infty C)) = 0
\end{equation}
Using the previously calculated scalar values of $A$ and $C$ and using Equations (\ref{eq:eq16}) and (\ref{eq:eq17}) yields:
\begin{equation}
	\begin{split}
		p_d &= 1 + L_\infty \\
		&= 1 - \frac{\hat{P}_\infty + Q_\infty}{\hat{P}_\infty + Q_\infty + R_\infty} \\
		&= \frac{R_\infty}{\hat{P}_\infty + Q_\infty + R_\infty} \\
		&= \frac{2R_\infty}{-Q_\infty + \sqrt{Q_\infty^2 + 4R_\infty Q_\infty} + 2Q_\infty + 2R_\infty} \\
		&= \cfrac{2}{\cfrac{Q_\infty}{R_\infty} + 2 + \sqrt{\left(\cfrac{Q_\infty}{R_\infty}\right)^2 + \cfrac{4Q_\infty}{R_\infty}}}
	\end{split}
\end{equation}

\noindent From this equation, one can deduce that the pole goes to zero with increasing $\frac{Q}{R}$. Inversely, for decreasing ratio ($\frac{Q}{R} \rightarrow 0$), the value of the pole shifts towards $1$. These conclusions are verified by Figure \ref{fig:poles_LQE}. For $\frac{Q}{R} = 0$, the pole lies on the unit circle, which implies that the system is marginally stable for this ratio. This is the only $\frac{Q}{R}$ - value that leads to instability, because, as depicted by the figure, the poles move towards the centre of the unit circle for increasing values of the ratio. In turn, it means that the system responds faster and faster. This can easily be explained: the larger $\frac{Q}{R}$, the more confidence in the measurement. Subsequently, the system is more sensitive to measurement noise, which complies with a faster, more nervous tracking of the system.

\begin{figure}[htp!]
	\centering
	\includegraphics[width=0.5\linewidth]{poles_LQE.eps}
	\caption{Closed loop poles of the Linear Quadratic Estimator for varying values of the ratio between $Q$ and $R$, respecitvely the covariance of the process noise and the covariance of the measurement noise.}
	\label{fig:poles_LQE}
\end{figure}



\newpage
\section{Implementation of a State Estimator and a State Feedback Controller}

\subsection{Values for K, Q and R}
\label{subsec:kqr}
The Kalman filter accounts for two types of noise. Firstly, the uncertainty about the system equations and the process disturbance inputs causes noise, which is modeled by the \textbf{process noise}. A disturbance input may e.g. be the slipping of the wheels when the motors are activated. Secondly, there is \textbf{measurement noise}, which comes from the inaccuracy of the sensor that measures the distance to the wall. The infrared rays sent out by the sensor may reflect in an incomplete fashion, causing the noise. 
\\\\
Firstly, the measurement noise covariance $R$ is directly calculated, based on the distance data obtained when the cart is standing still in front of a wall at a certain distance. Next, the \texttt{Matlab} command \texttt{cov()} returns the wanted value of $R$. In this case, $R = 8.4588 e^{-6}$ m$^2$.
\\\\
Secondly, the process noise covariance is calculated by multiplying $R$ with an arbitrary constant. $\frac{Q}{R} = 10$ seems fit for this system, which implies that one has slightly more trust in the measurements than in the model. This leads to $Q = 8.4588 e^{-5}$ m$^2$.
\\\\
Next, as discussed in Subsection \ref{subsec:tf}, the value of the state feedback gain $K$ is a trade-off between response time and control effort and is restricted to $0 < K < 100$ Hz for stability reasons. Furthermore, it is important that the pole of the state estimator is faster than the closed loop pole of the state feedback controller. Subsequently, Figure \ref{fig:poles_LQE} shows that it is preferred that $K$ is chosen in a way that the pole of the closed loop system is bigger than $0.5$.
\\\\
In order to determine the static feedback gain, experiments are conducted with different values of $K$. In these experiments, the cart starts at a position of $x = -0.3$ m, which is the maximum distance at which the distance sensor gives reliable results. The desired position of the cart is then set to $x = -0.05$ m, the minimum distance of the operating range of the sensor. This is done in order to judge whether or not the chosen $K$ leads to an input voltage of $> 12$ V when the cart has to bridge the biggest possible distance. An input voltage that exceeds this limit means that the DC motor saturates, thus $K$ would be too high. These experiments reveal that a static feedback gain of $2.4$ Hz does not cross this limit, while also ensuring a fast enough response time.
\\\\
Lastly, a value for the initial state covariance $P_{0|0}$ is settled. In this report, it is assumed that the cart can almost certainly be placed within $1.5$ cm in front or behind the intended initial state $x_{\text{init}}$. Following the \textit{68-95-99.7 rule}\footnote{"In statistics, the 68–95–99.7 rule, also known as the empirical rule, is a shorthand used to remember the percentage of values that lie within an interval estimate in a normal distribution: 68\%, 95\%, and 99.7\% of the values lie within one, two, and three standard deviations of the mean, respectively." \cite{68rule}} leads to $P_{0|0} = \left(\frac{0.015}{3}\right)^2 = 2.5e^{-5}$ m$^2$.
\\\\
Summarized:
\begin{multicols}{2}
	\begin{itemize}
		\item $K = 2.4$ Hz
		\item $R = 8.4588 e^{-6}$ m$^2$
		\item $Q = 8.4588 e^{-5}$ m$^2$
		\item $P_{0|0} = 2.5e^{-5}$ m$^2$
	\end{itemize}
\end{multicols}


\subsection{Step Response for varying K}
Figure \ref{fig:variable_K} depicts the measured response of the system to a step signal as position reference at $t = 0$. The cart starts at a distance of $0.25m$ from the wall and the desired position is $0.05m$ from the wall. This is done for different values of the static feedback gain $K$. This way, the explanation given in Subsection \ref{subsec:tf} is experimentally verified. Indeed, the bigger $K$, the closer the pole of the closed loop system lies to the origin, the faster the response. Inversely, a smaller $K$ corresponds to a slower responding system.
\\\\
The consequence that a faster response time comes with a larger cost in terms of actuation signal is also visualized in Figure \ref{fig:variable_K}. Ditto for smaller values of $K$. On this figure, the low-level control signals are plotted for the same values as the previous figure, which clearly shows the trade-off as explained in Subsection \ref{subsec:tf} and \ref{subsec:kqr}.
\\\\
As previously mentioned, there is a theoretical limitation on the value of $K$. It must oblige $0 < K < 200$ Hz in order to have a stable system. Furthermore, there are some practical limitations as well. $K$ must be less than or equal to $2.4$ Hz so the DC motors do not saturate when the cart travels from $x = -0.3$ m to $x = -0.05$ m. Also, $K$ cannot be too high, otherwise there is the risk that the wheels slip. 
\\\\
With all of this in mind, $K = 2.4$ Hz is chosen, which was also discussed in the previous Subsection.

\begin{figure*}[htp!]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{response_variable_K.eps}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.478\textwidth}  
		\centering 
		\includegraphics[width=\textwidth]{voltage_variable_K.eps}
	\end{subfigure}
	\caption{Response and corresponding control signals of the closed-loop system to a step signal as position reference for varying values of the state feedback gain K.} 
	\label{fig:variable_K}
\end{figure*}


\subsection{Step Response for varying Q and R}
\label{subsec:33}
Next, the same step signal is applied, but now with varying values of the process noise covariance $Q$ and measurement noise covariance $R$, while $K = 2.4$ Hz. The evolution of the state estimate covariance $\hat{P}_{k|k}$ and the corresponding Kalman gain $L_k$ is examined and depicted in Figure \ref{fig:variable_rho}. 
\\\\
Because $R$ is a measured quantity and $Q$ is chosen with respect to $R$, only $Q$ is varied. However, conceptually, $R$ could also be varied while $Q$ remains constant. This is why it is indicated on the figure that the ratio $\rho = \frac{Q}{R}$ changes.

\begin{figure*}[htp!]
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{phat.eps}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.48\textwidth}  
		\centering 
		\includegraphics[width=\textwidth]{L.eps}
	\end{subfigure}
	\caption{Evolution of the state estimate covariance $\hat{P}_{k|k}$ and the corresponding Kalman gain $L_k$ for different values of $\rho = \frac{Q}{R}$.} 
	\label{fig:variable_rho}
\end{figure*}

\noindent It immediately stands out that both $\hat{P}_{k|k}$ and $L_k$ are constant in time for a certain $\rho$, and thus equal to the steady state gains. This is actually not entirely true, as there is a very short transition from the initial values to the steady state values as soon as the Kalman filter is enabled. Due to it being very short, it is not visible on the plots. 
\\\\
In Figure \ref{fig:error_L}, the relative error between this experimentally determined steady state Kalman gain and the LQE estimator gain is depicted. As pointed out in Subsection \ref{subsec:lqe}, the steady state Kalman gain $L_\infty$ is as good as equal to the gain of an LQE. This is confirmed by the magnitude of the error in Figure \ref{fig:error_L}, which is in the order of $10^{-7}$. Figure \ref{fig:error_P} indicates the relative error between the experimental steady state state estimator gain and theoretical gain of Equation \ref{eq:eq16}
\\\\
The analysis of Subsection \ref{subsec:ss} showed that the closed loop pole of the LQE goes to zero with increasing $\rho$. This corresponds a to quickly responding system, which explains the values of $L_k$ in Figure \ref{fig:variable_rho} for large $\rho$. Namely, a fast response demands that the correction step has a great influence, which in turn correlates with a large estimator gain (in absolute value). This is exactly what can be seen in the right plot. Furthermore, Equation (\ref{eq:eq13}) showed that $\hat{P}_{k|k}$ converges towards $R_k$ for $\rho \rightarrow \infty$. The left plot of Figure \ref{fig:variable_rho} confirms this, as $R_k = R = 8.4588 e^{-6}$ m$^2$.
\\\\
Inversely, for a decreasing ratio ($\rho \rightarrow 0$), the value of the closed loop pole shifts towards $1$, corresponding to a marginally stable system. For this case, the correction step should be negligible, which is in line with a gain of $0$. Again, Figure \ref{fig:variable_rho} indicates that $L_k$ comes closer to $0$ for decreasing $\rho$. Also, Equation (\ref{eq:eq13}) prompts once more that that the correction step can be omitted for $\rho \rightarrow 0$, as it leads to $\hat{P}_{k|k} = \hat{P}_{k|k-1}$.
\\\\
These two cases for $\rho$ are also confirmed by Subsection \ref{subsec:kalman_gain}, where $L_{k+1}$ is theoretically calculated for $Q_k \rightarrow \infty$ and $R_k \rightarrow \infty$, respectively equivalent with $\rho \rightarrow \infty$ and  $\rho \rightarrow 0$, which yielded $L_{k+1}  = -1$ and $L_{k+1}  = 0$.

\begin{figure*}[htp!]
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{error_L.eps}
		\caption{Relative error between the \textbf{experimental} steady state Kalman gain and \textbf{theoretical} LQE estimator gain.}
		\label{fig:error_L}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.48\textwidth}  
		\centering 
		\includegraphics[width=\linewidth]{error_P.eps}
		\caption{Relative error between the \textbf{experimental} steady state state estimator gain and \textbf{theoretical} gain of Equation \ref{eq:eq16}.}
		\label{fig:error_P}
	\end{subfigure}
	\caption{Relative errors between experimental gains and theoretical gains, calculated using \texttt{dlqr} and Equation \ref{eq:eq16}.} 
	\label{error2}
\end{figure*}

\subsection{Evolution of NIS and SNIS}
In this Subsection, the consistency of the Kalman filter is checked using two statistical tests based on innovations: NIS and SNIS. The Normalized Innovation Squared (NIS) is calculated as:
\begin{equation}
	NIS_k = \nu_k^T S_k^{-1}\nu_k
\end{equation}
where $S_k$ is the innovation covariance and the innovation (or measurement residual) itself is:
\begin{equation}
	\nu_k = y_k - C \hat{x}_{k|k-1}
\end{equation}
So the NIS becomes:
\begin{equation}
	NIS_k = (y_k - \hat{x}_{k|k-1})^2 S_k^{-1}
\end{equation}
The Summed Normalized Innovation Squared (SNIS) is then equal to:
\begin{equation}
	SNIS_k = \sum_{j = k-M+1}^{k} \nu_j^T S_j^{-1}\nu_j = \sum_{j = k-M+1}^{k} (y_j - \hat{x}_{j|j-1})^2 S_j^{-1}
\end{equation}
which boils down to the sum of the latest M NIS-values. This way, the expressions for $NIS_k$ and $SNIS_k$ only depend on variables that can be obtained from the experiments. Remember, $y_j$ and $\hat{x}_{j|j-1}$ are respectively the measured output and the a priori state estimate at time instance $j$. Further, both $NIS_k$ and $SNIS_k$ are $\chi^2$-distributed, with respectively $1$ and $M$ degrees of freedom.
\\\\
In Figure \ref{fig:SNIS}, the NIS and SNIS are plotted for the different experiments of Subsection \ref{subsec:33}. One can see that the highest values are reached for $Q = 8.4588\cdot10^{-8}$, or $\rho = 0.01$, thus yielding the most optimal ratio between the process noise covariance $Q$ and measurement noise covariance $R$. However, these values are not nearly high enough to conclude that the Kalman filter is consistent. For this, one would need NIS and SNIS to approach $95\%$. This overall inconsistency may be caused by modeling errors, which includes an incorrect system model (state and/or measurement equation), an incorrect noise model (Gaussian noise with zero mean and given covariance) or an incorrect initial state estimate and/or its covariance. 


\begin{figure}[htp!]
	\centering
	\includegraphics[width =0.45\linewidth]{SNIS_1000.eps}
	\includegraphics[width =0.45\linewidth]{SNIS_100}
	\includegraphics[width =0.45\linewidth]{SNIS_10.eps}
	\includegraphics[width =0.45\linewidth]{SNIS_1}
	\includegraphics[width =0.45\linewidth]{SNIS_01.eps}
	\includegraphics[width =0.45\linewidth]{SNIS_001}
	\includegraphics[width =0.45\linewidth]{SNIS_0001.eps}
	\caption{NIS and SNIS for varying $Q$ and for $R = 8.4588\cdot10^{-6}$.}
	\label{fig:SNIS}
\end{figure}

\newpage
\subsection{Wrong initial Estimation for the Position}
\label{subsec:35}
Now, a step signal as position reference is again applied for different values of $\rho$ at $t = 0$, just as in Subsection \ref{subsec:33}. However, the initial estimation for the position $\hat{x}_{0|0}$ is chosen wrong on purpose. In reality, the cart starts from a position $x = -0.25$ m, but $\hat{x}_{0|0}$ is taken at $-0.05$ m. So when the position reference of $x = -0.1$ m is applied, the cart should theoretically move backwards before heading to the reference at $-0.1$ m.
\\\\
Figure \ref{fig:wrong_pos} depicts the measured and the estimated response for each $\rho$ that has been used in the assignment so far, while still $K = 2.4$ Hz. For $\rho = 0.001$, the estimate converges the slowest to the measurements. Also, it is not really visible that the cart first moves backwards, as this is only for a very short amount of time.
\\\\
From the other plots, it is obvious that the estimated distance converges faster to the measured distance for increasing $\rho = \frac{Q}{R}$. E.g. for $\rho = 1000$, the lines even seem to be coinciding. Only when zooming in, one can see the difference. This conclusion is logical, as a bigger $\rho$ implies that one has less confidence in the model, or equivalently, more confidence in the measurement. That leads in turn to the fact that the estimated distance follows the measured distance more meticulous. 

\begin{figure}[htp!]
	\centering
	\includegraphics[width =0.45\linewidth]{wrong_pos_1000.eps} \quad
	\includegraphics[width =0.45\linewidth]{wrong_pos_100}
	\includegraphics[width =0.45\linewidth]{wrong_pos_10.eps}\quad
	\includegraphics[width =0.45\linewidth]{wrong_pos_1}

\end{figure}
\begin{figure}[htp!]
	\centering
	\includegraphics[width =0.45\linewidth]{wrong_pos_01.eps}\quad
	\includegraphics[width =0.45\linewidth]{wrong_pos_001}
	\includegraphics[width =0.45\linewidth]{wrong_pos_0001.eps}
	\caption{Measured and estimated response for varying $Q$ and for $R = 8.4588\cdot10^{-6}$ m$^2$.}
	\label{fig:wrong_pos}
\end{figure}

\newpage
\subsection{Design of a State Estimator using Pole Placement}
Lastly, a state estimator is implemented using pole placement, such that the closed loop pole of the estimator is ten times slower than the closed loop pole of the state feedback controller that was used in this assignment. To this extent, the latter pole is first transformed back to the continuous space:
\begin{equation}
	\begin{split}
		p_{d, \text{feedback}} &= 1 - T_s K = 0.9760 \\
		\iff p_{c, \text{feedback}} &= \frac{\text{ln}(p_{d, \text{feedback}})}{T_s} = - 2.4293
	\end{split}
\end{equation}
Next, the pole of the estimator is calculated and transformed back to the discrete space:
\begin{equation}
	\begin{split}
		p_{c, \text{estimator}} &= \frac{p_{c, \text{feedback}}}{10} = - 0.24293 \\
		\iff p_{d, \text{estimator}} &= \text{exp}( p_{c, \text{feedback}} T_s) = 0.9976
	\end{split}
\end{equation}
Then, Ackermann's formula determines the estimator gain $L_{place}$, which is computed in \texttt{Matlab} using the command \texttt{acker($A', C', p_{d, \text{estimator}}$)}. This yields $L_{place} = -0.0024$. Yet again, a step signal as position reference is applied at $t = 0$ with the same wrong initial position estimate $\hat{x}_{0|0} = -0.05$ m as in Subsection \ref{subsec:35}. However, the position reference is now taken at $-0.2$ m instead of $-0.1$ m.
\\\\
Finally, Figure \ref{fig:pole_placement} visualizes the measured and estimated distance with $K = 2.4$ Hz, $R = 8.4588\cdot10^{-6}$  m$^2$ and $Q = 8.4588\cdot10^{-5}$  m$^2$. The scaling of the x-axis clearly indicates the effect of the slow estimator pole: it takes a relatively long time before the measured distance reaches the reference. Also, there is a large difference between the estimated and the measured response. This shows that, in this case, $\rho$ is too small to have a satisfactory control performance. Furthermore, due to the slow estimator, the effect of the wrong position estimate is clearly visible: the cart goes the opposite direction for a significant amount of time, whereas this was almost not visible when using a Kalman filter.
\\\\
As mentioned in Subsection \ref{subsec:kqr}, it is important that the pole of the state estimator is faster than the pole of the state feedback estimator. Thus, in order for the pole placement to be beneficial, the discrete time closed loop pole of the estimator should be placed closer to the origin, instead of the unit circle. Though, one should take care that the required control effort is not too high, so that saturation of the motors is avoided. 
\begin{figure}[htp!]
	\centering
	\includegraphics[width = 0.6\linewidth]{pole_placement.eps}
	\caption{Measured and estimated response for the system with a state estimator designed using pole placement.}
	\label{fig:pole_placement}
\end{figure}




















\newpage
\bibliographystyle{plain}
\bibliography{bibliography.bib}


\end{document}